{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "C4_W2_Lab_1_features_and_labels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDcwEEXObQ-R"
      },
      "source": [
        "**Note:** This notebook can run using TensorFlow 2.5.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6eq-RBcQ_Zr"
      },
      "source": [
        "#!pip install tensorflow==2.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOjujz601HcS"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asEdslR_05O_"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "for val in dataset:\n",
        "   print(val.numpy())\n",
        "\n",
        "# 예\n",
        "# 0\n",
        "# 1\n",
        "# 2\n",
        "# 3\n",
        "# 4\n",
        "# 5\n",
        "# 6\n",
        "# 7\n",
        "# 8\n",
        "# 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1)\n",
        "for window_dataset in dataset:\n",
        "   for val in window_dataset:\n",
        "     print(val.numpy(), end = \" \")\n",
        "   print()\n",
        "\n",
        "# 예\n",
        "\n",
        "# 0 1 2 3 4 \n",
        "# 1 2 3 4 5 \n",
        "# 2 3 4 5 6 \n",
        "# 3 4 5 6 7 \n",
        "# 4 5 6 7 8 \n",
        "# 5 6 7 8 9 \n",
        "# 6 7 8 9 \n",
        "# 7 8 9 \n",
        "# 8 9 \n",
        "# 9 "
      ],
      "metadata": {
        "id": "J1MZx8c7XWGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrv_ghSt1lgQ"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1)\n",
        "for window_dataset in dataset:\n",
        "  for val in window_dataset:\n",
        "    print(val.numpy(), end=\" \")\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLEq6MG-2DN2"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "for window_dataset in dataset:\n",
        "  for val in window_dataset:\n",
        "    print(val.numpy(), end=\" \")\n",
        "  print()\n",
        "\n",
        "# 그냥 dataset 안을 window_dataset으로 loop 돌려서 보면 이렇게 나온다.\n",
        "# <_VariantDataset shapes: (), types: tf.int64>\n",
        "# <_VariantDataset shapes: (), types: tf.int64>\n",
        "# <_VariantDataset shapes: (), types: tf.int64>\n",
        "# <_VariantDataset shapes: (), types: tf.int64>\n",
        "# <_VariantDataset shapes: (), types: tf.int64>\n",
        "# <_VariantDataset shapes: (), types: tf.int64>\n",
        "\n",
        "# 결과\n",
        "# 0 1 2 3 4 \n",
        "# 1 2 3 4 5 \n",
        "# 2 3 4 5 6 \n",
        "# 3 4 5 6 7 \n",
        "# 4 5 6 7 8 \n",
        "# 5 6 7 8 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ9CAHlJ2ODe"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "for window in dataset:\n",
        "  print(window.numpy())\n",
        "# 예\n",
        "# [0 1 2 3 4]\n",
        "# [1 2 3 4 5]\n",
        "# [2 3 4 5 6]\n",
        "# [3 4 5 6 7]\n",
        "# [4 5 6 7 8]\n",
        "# [5 6 7 8 9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DryEZ2Mz2nNV"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "for x,y in dataset:\n",
        "  print(x.numpy(), y.numpy())\n",
        "\n",
        "# 예\n",
        "# [0 1 2 3] [4]\n",
        "# [1 2 3 4] [5]\n",
        "# [2 3 4 5] [6]\n",
        "# [3 4 5 6] [7]\n",
        "# [4 5 6 7] [8]\n",
        "# [5 6 7 8] [9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tl-0BOKkEtk"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "dataset = dataset.shuffle(buffer_size=10) #데이터 갯수와 동일하거나 더 커야함. 작으면 초반 N까지만 shuffle하고 뒤는 안되게되므로..\n",
        "for x,y in dataset:\n",
        "  print(x.numpy(), y.numpy())\n",
        "\n",
        "# 예\n",
        "# [5 6 7 8] [9]\n",
        "# [2 3 4 5] [6]\n",
        "# [3 4 5 6] [7]\n",
        "# [0 1 2 3] [4]\n",
        "# [1 2 3 4] [5]\n",
        "# [4 5 6 7] [8]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa0PNwxMGapy"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "dataset = dataset.shuffle(buffer_size=10)\n",
        "dataset = dataset.batch(2).prefetch(1) #x, y를 배치사이즈에 맞게 묶어서 만들어준다.\n",
        "for x,y in dataset:\n",
        "  print(\"x = \", x.numpy())\n",
        "  print(\"y = \", y.numpy())\n",
        "\n",
        " # 예\n",
        "#x =  [[1 2 3 4]\n",
        "# [4 5 6 7]]\n",
        "#y =  [[5]\n",
        "# [8]]\n",
        "#x =  [[0 1 2 3]\n",
        "# [2 3 4 5]]\n",
        "#y =  [[4]\n",
        "# [6]]\n",
        "#x =  [[5 6 7 8]\n",
        "# [3 4 5 6]]\n",
        "#y =  [[9]\n",
        "# [7]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FUnEZPDRcqGE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}